{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1.\n",
    "Обязательная часть  \n",
    "Будем парсить страницу со свежеми новостям на habr.com/ru/all/.  \n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово.  \n",
    "Эти слова определяем в начале кода в переменной, например:  \n",
    "KEYWORDS = ['python', 'парсинг']  \n",
    "\n",
    "Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы).  \n",
    "В итоге должен формироваться датафрейм вида  <дата> - <заголовок> - <ссылка>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORDS = ['python', 'парсинг']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('http://habr.com/ru/all/')\n",
    "res_soup = BeautifulSoup(res.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "#данные со страницы с постами\n",
    "page = res_soup.find_all('div', class_='posts_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'сегодня в 10:21'"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получим данные по времени поста\n",
    "date = list(map(lambda x: x.find_all('span', class_='post__time'), page))\n",
    "#date = res_soup.findAll('span', {'class': 'post__time'}) еще вариант решения\n",
    "date[0][0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Гигантский ленивец — первое домашнее животное?'"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#получим данные по заголовку поста\n",
    "lable = list(map(lambda x: x.find_all('h2', class_='post__title'), page))\n",
    "lable[0][0].get_text().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://habr.com/ru/post/537748/'"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#получим ссылку постов\n",
    "link = list(map(lambda x: x.find('a').get('href'), lable[0]))\n",
    "link[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Дополнительная часть (необязательная)  \n",
    "Улучшить скрипт так, чтобы он анализировал не только preview-информацию статьи, но и весь текст статьи целиком.  \n",
    "Для этого потребуется получать страницы статей и искать по тексту внутри этой страницы.  \n",
    "Итоговый датафрейм формировать со столбцами: <дата> - <заголовок> - <ссылка> - <текст_статьи>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_text = requests.get('https://habr.com/ru/company/skillfactory/blog/537522/')\n",
    "res_soup_text = BeautifulSoup(res_text.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "#получим данные их блока с текстом\n",
    "text = res_soup_text.find_all('div', class_='post__text post__text-html post__text_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция\n",
    "def get_info_from_hubr(res):\n",
    "    df = pd.DataFrame(columns=['date', 'lable', 'link', 'text'])\n",
    "    date_ = []\n",
    "    lable_ = []\n",
    "    link_ = []\n",
    "    text_ = []\n",
    "    res_soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    #данные со страницы с постами\n",
    "    page = res_soup.find_all('div', class_='posts_list')\n",
    "    \n",
    "    # получим данные по времени поста\n",
    "    date = list(map(lambda x: x.find_all('span', class_='post__time'), page))\n",
    "    for i in date[0]:\n",
    "        date_.append(i.get_text())\n",
    "    df['date'] = date_\n",
    "    \n",
    "    #получим данные по заголовку поста\n",
    "    lable = list(map(lambda x: x.find_all('h2', class_='post__title'), page))\n",
    "    for i in lable[0]:\n",
    "        lable_.append(i.get_text().replace('\\n', ''))\n",
    "    df['lable'] = lable_\n",
    "    \n",
    "    #получим ссылку постов\n",
    "    link = list(map(lambda x: x.find('a').get('href'), lable[0]))\n",
    "    for i in link:\n",
    "        link_.append(i)\n",
    "    df['link'] = link_\n",
    "    \n",
    "    for i in link:\n",
    "        link_.append(i)\n",
    "    for i in link:\n",
    "        res_text = requests.get(i)\n",
    "        res_soup_text = BeautifulSoup(res_text.text, 'html.parser')\n",
    "        #получим данные их блока с текстом\n",
    "        text = res_soup_text.find_all('div', class_='post__text post__text-html post__text_v1')\n",
    "        if text == []:\n",
    "            text_.append('Nan')\n",
    "        elif text != '':\n",
    "            text = res_soup_text.find_all('div', class_='post__text post__text-html post__text_v1')\n",
    "            text_.append(text[0].get_text())\n",
    "    df['text'] = text_\n",
    "    #добавил фильтрацию по заголовку\n",
    "    df = df[(df['lable'].str.contains(KEYWORDS[0] or KEYWORDS[1]))]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lable</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>вчера в 22:37</td>\n",
       "      <td>Многопоточное скачивание файлов с ftp python-с...</td>\n",
       "      <td>https://habr.com/ru/post/537774/</td>\n",
       "      <td>Nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date                                              lable  \\\n",
       "16  вчера в 22:37  Многопоточное скачивание файлов с ftp python-с...   \n",
       "\n",
       "                                link text  \n",
       "16  https://habr.com/ru/post/537774/  Nan  "
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_info_from_hubr(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.\n",
    "Обязательная часть  \n",
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса Avast Hack Ckeck.   Список email-ов задаем переменной в начале кода:  \n",
    "EMAIL = [xxx@x.ru, yyy@y.com]  \n",
    "В итоге должен формироваться датафрейм со столбцами: <почта> - <дата утечки> - <источник утечки> - <описание   утечки>  \n",
    "Подсказка: сервис работает при помощи \"скрытого\" API. Внимательно изучите post-запросы.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.avast.com/hackcheck/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.post(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_soup = BeautifulSoup(res.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head><title>405 Not Allowed</title></head>\n",
       "<body>\n",
       "<center><h1>405 Not Allowed</h1></center>\n",
       "<hr/><center>nginx</center>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
